{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model,load_model\n",
    "from keras import layers\n",
    "from keras.layers import (Input,Activation,Concatenate,Add,Dropout,BatchNormalization,Conv2D,DepthwiseConv2D\n",
    "                        ,ZeroPadding2D,AveragePooling2D,Lambda,Conv2DTranspose, MaxPooling2D, concatenate\n",
    "                        ,Dropout,UpSampling2D,Flatten)\n",
    "from keras.engine import Layer,InputSpec\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "import gc\n",
    "import keras\n",
    "from keras.layers import Lambda, Input, Dense, LeakyReLU, Concatenate,Dropout,RepeatVector,Reshape,Flatten\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize as norm\n",
    "from collections import Counter\n",
    "from keras import callbacks\n",
    "\n",
    "import random\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of image: i.e. the image will be RESIZE X RESIZE\n",
    "RESIZE = 28\n",
    "\n",
    "# Number of latent z's\n",
    "LATENT_DIM = 300\n",
    "\n",
    "# Number of neurons in each hidden layer\n",
    "INTERMEDIATE_DIM = 1000\n",
    "\n",
    "# Number of classes\n",
    "CLASSES = 10\n",
    "\n",
    "# Number of monte  carlo samples (see paper)\n",
    "MC_SAMPLES = 1\n",
    "\n",
    "BATCH_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2():\n",
    "    #Shape of flattened image\n",
    "    input_shape=(RESIZE*RESIZE,)\n",
    "    #inputs\n",
    "    img_input = Input(shape=input_shape)\n",
    "    #labels with empty second half\n",
    "    y_full = Input(shape=(CLASSES,))\n",
    "    #labels with empty labels removed\n",
    "    y_input,y_val = Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(y_full)\n",
    "    \n",
    "    def gaussian_sampling(args):\n",
    "        \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "        # Arguments\n",
    "            args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "        # Returns\n",
    "            z (tensor): sampled latent vector\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        z_mean_repeat = RepeatVector(MC_SAMPLES)(z_mean)\n",
    "        z_log_var_repeat = RepeatVector(MC_SAMPLES)(z_log_var)\n",
    "        epsilon = K.random_normal(shape=K.shape(z_mean_repeat))\n",
    "        z_sample = z_mean_repeat + K.exp(0.5 * z_log_var_repeat) * epsilon\n",
    "        return z_sample\n",
    "    \n",
    "    \n",
    "    #Implements a q(y|x) NN with two hidden units that outputs the probability of each img being a certain label\n",
    "    q_y__x_layer1 = Dense(INTERMEDIATE_DIM)(img_input)\n",
    "    q_y__x_layer1_act =LeakyReLU(alpha = .03)(q_y__x_layer1)\n",
    "    q_y__x_layer2 = Dense(INTERMEDIATE_DIM)((q_y__x_layer1_act))\n",
    "    q_y__x_layer2_act = LeakyReLU(alpha = .03)(q_y__x_layer2)\n",
    "    q_y__x_output = Dense(CLASSES, activation = 'softmax',name = 'q_y__x')(q_y__x_layer2_act)\n",
    "    \n",
    "    # Seperates out the predictions that we have labels for and those that we do not\n",
    "    y_sup,y_un= Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(q_y__x_output) \n",
    "    # For the integrating out approach, we repeat the input matrix x, and construct a target (bs * n_y) x n_y\n",
    "    # Example of input and target matrix for a 3 class problem and batch_size=2. 2D tensors of the form\n",
    "    #               x_repeat                     t_repeat\n",
    "    #  [[x[0,0], x[0,1], ..., x[0,n_x]]         [[1, 0, 0]\n",
    "    #   [x[1,0], x[1,1], ..., x[1,n_x]]          [1, 0, 0]\n",
    "    #   [x[0,0], x[0,1], ..., x[0,n_x]]          [0, 1, 0]\n",
    "    #   [x[1,0], x[1,1], ..., x[1,n_x]]          [0, 1, 0]\n",
    "    #   [x[0,0], x[0,1], ..., x[0,n_x]]          [0, 0, 1]\n",
    "    #   [x[1,0], x[1,1], ..., x[1,n_x]]]         [0, 0, 1]]\n",
    "    one_hot = Lambda( lambda x: K.constant(np.eye(CLASSES, dtype=int)))(img_input)\n",
    "    #if garbage values change tile to repeat\n",
    "    dummy_y = Lambda( lambda x: K.tile(x, [(BATCH_SIZE//2),1] ))(one_hot)\n",
    "    \n",
    "    y = Concatenate(axis=0)([y_input,dummy_y])\n",
    "    \n",
    "    # turn x,y,z into x,x,x,y,y,y,z,z,z with the number of repeats being the number of classes\n",
    "    img_sup,img_un =Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(img_input) \n",
    "    rep_img_un = Lambda(lambda x: K.repeat_elements(x,rep=CLASSES,axis = 0))(img_un)\n",
    "    rep_img_input = Concatenate(axis=0)([img_sup,rep_img_un])\n",
    "    \n",
    "    #Implements a q(z|y,x) NN with two hidden units that outputs the parameters to a gaussian distribution\n",
    "    # for labeled data and for unlabeled outputs parameters for each possible y\n",
    "    q_z__y_x_concat = Concatenate()([rep_img_input,y])\n",
    "    q_z__y_x_layer1 = Dense(INTERMEDIATE_DIM)(q_z__y_x_concat)\n",
    "    q_z__y_x_layer1_act = LeakyReLU(alpha = .03)(q_z__y_x_layer1)\n",
    "    q_z__y_x_layer2 = Dense(INTERMEDIATE_DIM)(q_z__y_x_layer1_act)\n",
    "    q_z__y_x_layer2_act = LeakyReLU(alpha = .03)(q_z__y_x_layer2)\n",
    "    q_z__y_x_mean = Dense(LATENT_DIM,name = 'q_z__y_x_mean')(q_z__y_x_layer2_act)\n",
    "    rep_q_z__y_x_mean = RepeatVector(MC_SAMPLES)(q_z__y_x_mean)\n",
    "    q_z__y_x_log_var = Dense(LATENT_DIM,name = 'q_z__y_x_log_var')(q_z__y_x_layer2_act)\n",
    "    rep_q_z__y_x_log_var = RepeatVector(MC_SAMPLES)(q_z__y_x_log_var)\n",
    "    q_z__y_x_output = Lambda(gaussian_sampling,name = 'q_z__y_x')([q_z__y_x_mean,q_z__y_x_log_var])\n",
    "\n",
    "    # Implements a p(x|y,z) NN with two hidden units that outputs the parameters to a bernoulli distribution\n",
    "    # for labeled data and for unlabeled outputs parameters for each possible y\n",
    "    p_x__y_z_concat = Concatenate()([y ,Flatten()(q_z__y_x_output)])\n",
    "    p_x__y_z_layer1 = Dense(INTERMEDIATE_DIM)(p_x__y_z_concat)\n",
    "    p_x__y_z_layer1_act = LeakyReLU(alpha = .03)(p_x__y_z_layer1)\n",
    "    p_x__y_z_layer2 = Dense(INTERMEDIATE_DIM)(p_x__y_z_layer1_act)\n",
    "    p_x__y_z_layer2_act = LeakyReLU(alpha = .03)(p_x__y_z_layer2)\n",
    "    p_x__y_z_mean = Dense(RESIZE*RESIZE,activation = 'sigmoid',name = 'p_x__y_z_mean')(p_x__y_z_layer2_act)\n",
    "    #p_x__y_z_log_var = Dense(resize*resize,name = 'p_x__a_y_z_log_var')(p_x__a_y_z_layer2_act)\n",
    "    #p_x__y_z_output = Lambda(gaussian_sampling,name = 'p_x__a_y_z')([p_x__a_y_z_mean, p_x__a_y_z_log_var]) \n",
    "    \n",
    "    def gaussian_ll(args):\n",
    "        # Calculates the log liklihood of a point x under a gaussian distribution parameterized by mu and log_var\n",
    "        x , mu, log_var = args\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - log_var/2 - ((x - mu)/(2*K.exp(log_var) + 1e-8))*(x - mu)\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "    \n",
    "    def unit_gaussian_ll(args):\n",
    "        # Calculates the log liklihood of a point x under a unit gaussian distribution\n",
    "        x = args\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - (x)**2/2\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "\n",
    "        \n",
    "    def log_pz(y_true,y_pred):\n",
    "        # Calculates the log liklihood that the sampled 'z' is under the unit gaussian distributions \n",
    "        #, then weights the unsupervised samples according to how likely their asscociated y value was.\n",
    "        # (as predicted by p(y|x))\n",
    "        flat_y_un = K.reshape(y_un,shape = [-1])\n",
    "        ones = K.ones(shape = (BATCH_SIZE//2))\n",
    "        weights = K.concatenate([ones,flat_y_un],0)\n",
    "        loss_per_point = weights*K.mean(unit_gaussian_ll(q_z__y_x_output),axis = 1)\n",
    "        split = tf.split(loss_per_point, num_or_size_splits=CLASSES+1 ,axis=0)\n",
    "        sup_loss = split[0]\n",
    "        un = K.concatenate(split[1:])\n",
    "        un_loss = K.sum(K.reshape(un,[BATCH_SIZE//2,CLASSES]),axis = 1)\n",
    "        loss = K.concatenate([sup_loss,un_loss])\n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def log_qz(y_true,y_pred):\n",
    "        # Calculates the log liklihood that the sampled 'z' is under the gaussian distributions predicted by\n",
    "        # q(z|y,x), then weights the unsupervised sampled according to how likely their asscociated y value was\n",
    "        #(as predicted by p(y|x))\n",
    "        flat_y_un = K.reshape(y_un,shape = [-1])\n",
    "        ones = K.ones(shape = (BATCH_SIZE//2))\n",
    "        weights = K.concatenate([ones,flat_y_un],0)\n",
    "        loss_per_point = weights*K.mean(gaussian_ll([q_z__y_x_output,rep_q_z__y_x_mean,rep_q_z__y_x_log_var]),axis = 1)\n",
    "        split = tf.split(loss_per_point, num_or_size_splits=CLASSES+1 ,axis=0)\n",
    "        sup_loss = split[0]\n",
    "        un = K.concatenate(split[1:])\n",
    "        un_loss = K.sum(K.reshape(un,[BATCH_SIZE//2,CLASSES]),axis = 1)\n",
    "        loss = K.concatenate([sup_loss,un_loss])\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def log_py(y_true,y_pred):\n",
    "        # Calculates the log liklihood that the all possible 'y' is under y's true distribution WHICH\n",
    "        # IS ASSUMED TO BE BALANCED CATAGORICLE, then weights the unsupervised sampled according to \n",
    "        #how likely their asscociated y value was (as predicted by p(y|x)).\n",
    "        flat_y_un = K.reshape(y_un,shape = [-1])\n",
    "        ones = K.ones(shape = (BATCH_SIZE//2))\n",
    "        weights = K.concatenate([ones,flat_y_un],0)\n",
    "        expected = K.ones_like(q_y__x_output)/CLASSES\n",
    "        concat = K.concatenate([y_input,y_un])\n",
    "        loss_per_point = K.categorical_crossentropy(expected,q_y__x_output)\n",
    "        return -loss_per_point\n",
    "        \n",
    "    \n",
    "    def log_px(y_true,y_pred):\n",
    "        # Calculates the log liklihood that the true images is under the gaussian distributions predicted by\n",
    "        # p(x|a,y,z), then weights the unsupervised sampled according to how likely their asscociated y value was\n",
    "        #(as predicted by p(y|a,x))\n",
    "        flat_y_un = K.reshape(y_un,shape = [-1])\n",
    "        ones = K.ones(shape = ((BATCH_SIZE//2)))\n",
    "        weights = K.concatenate([ones,flat_y_un],0)\n",
    "        loss_per_point = -weights*keras.losses.binary_crossentropy(rep_img_input,p_x__y_z_mean)\n",
    "        split = tf.split(loss_per_point, num_or_size_splits=CLASSES+1 ,axis=0)\n",
    "        sup_loss = split[0]\n",
    "        un = K.concatenate(split[1:])\n",
    "        un_loss = K.sum(K.reshape(un,[BATCH_SIZE//2,CLASSES]),axis = 1)\n",
    "        loss = K.concatenate([sup_loss,un_loss])\n",
    "        return loss\n",
    "    \n",
    "    def y_ent(y_true,y_pred):\n",
    "        # Caluclates the entropy of the unsupervised predicted y values\n",
    "        \n",
    "        flat_y_un = K.reshape(y_un,shape = [-1])\n",
    "        zero = K.zeros(shape = ((BATCH_SIZE//2)))\n",
    "        un = flat_y_un*K.log(flat_y_un)\n",
    "        un_loss = K.sum(K.reshape(un,[BATCH_SIZE//2,CLASSES]),axis = 1)\n",
    "\n",
    "        loss = K.concatenate([zero,un_loss])\n",
    "        return -loss\n",
    "       \n",
    "    def acc(y_true,y_pred):\n",
    "        # Calculates the raw accuracy of our y prediction for the images that we have labels for\n",
    "\n",
    "        return K.mean(keras.metrics.categorical_accuracy(y_input,y_sup))\n",
    "    \n",
    "    def y_class(y_true,y_pred):\n",
    "        # Calculates a supervised loss for the y predictions for the images that we have labels for\n",
    "        zero = K.zeros(shape = (BATCH_SIZE//2))\n",
    "        sup_loss = K.categorical_crossentropy(y_input,y_sup)\n",
    "\n",
    "        loss = K.concatenate([sup_loss,zero])\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def qy_loss(y_true,y_pred):\n",
    "        return K.mean(1*y_ent(y_true,y_pred) + -1*log_py(y_true,y_pred) + 10*y_class(y_true,y_pred))\n",
    "    \n",
    "    def qz_loss(y_true,y_pred):\n",
    "        return K.mean(log_qz(y_true,y_pred) + -1*log_pz(y_true,y_pred))\n",
    "    \n",
    "    def px_loss(y_true,y_pred):\n",
    "        return K.mean(-log_px(y_true,y_pred))\n",
    "    \n",
    "        \n",
    "    losses = {'q_y__x': qy_loss,'q_z__y_x': qz_loss, 'p_x__y_z_mean':px_loss}\n",
    "    \n",
    "    model = Model([img_input,y_full],[p_x__y_z_mean,q_y__x_output,q_z__y_x_output]\n",
    "                  , name = 'VAE')\n",
    "    model.compile(loss = losses,metrics = {'q_y__x':acc},optimizer = keras.optimizers.Adam(lr=.001,clipnorm=1.,clipvalue= .5))\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_m2_vae = M2()\n",
    "mnist_m2_vae.load_weights('MNIST_M2_VAE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of image: i.e. the image will be RESIZE X RESIZE\n",
    "RESIZE = 28\n",
    "\n",
    "# Number of latent z's\n",
    "LATENT_DIM = 300\n",
    "\n",
    "# Number of neurons in each hidden layer\n",
    "INTERMEDIATE_DIM = 1000\n",
    "\n",
    "# Number of classes\n",
    "CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of flattened image\n",
    "input_shape=(RESIZE*RESIZE,)\n",
    "\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "#Implements a q(y|x) NN with two hidden units that outputs the probability of each img being a certain label\n",
    "y = Dense(INTERMEDIATE_DIM)(img_input)\n",
    "y =LeakyReLU(alpha = .03)(y)\n",
    "y = Dense(INTERMEDIATE_DIM)(y)\n",
    "y = LeakyReLU(alpha = .03)(y)\n",
    "y = Dense(CLASSES, activation = 'softmax')(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_baseline = Model(img_input,y)\n",
    "mnist_baseline.compile(loss = 'categorical_crossentropy',metrics = ['categorical_accuracy'],optimizer = keras.optimizers.Adam(lr=.001,clipnorm=1.,clipvalue= .5))\n",
    "mnist_baseline.load_weights('MNIST_Baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of image: i.e. the image will be RESIZE X RESIZE\n",
    "RESIZE = 128\n",
    "\n",
    "#Number of possible classes for each pixel\n",
    "CLASSES = 21\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Used in the gumbel softmax sampling trick\n",
    "TEMPERATURE = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of this code comes from \n",
    "# https://github.com/bonlime/keras-deeplab-v3-plus/blob/master/model.py\n",
    "# however it has been heavily modified\n",
    "\n",
    "\n",
    "# Functions and layers that are used by the deeplab networks\n",
    "class BilinearUpsampling(Layer):\n",
    "    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n",
    "       Args:\n",
    "           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n",
    "           output_size: used instead of upsampling arg if passed!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n",
    "\n",
    "        super(BilinearUpsampling, self).__init__(**kwargs)\n",
    "\n",
    "        #self.data_format = K.normalize_data_format(data_format)\n",
    "        self.data_format = None\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        if output_size:\n",
    "            self.output_size = conv_utils.normalize_tuple(\n",
    "                output_size, 2, 'output_size')\n",
    "            self.upsampling = None\n",
    "        else:\n",
    "            self.output_size = None\n",
    "            self.upsampling = conv_utils.normalize_tuple(\n",
    "                upsampling, 2, 'upsampling')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.upsampling:\n",
    "            height = self.upsampling[0] * \\\n",
    "                input_shape[1] if input_shape[1] is not None else None\n",
    "            width = self.upsampling[1] * \\\n",
    "                input_shape[2] if input_shape[2] is not None else None\n",
    "        else:\n",
    "            height = self.output_size[0]\n",
    "            width = self.output_size[1]\n",
    "        return (input_shape[0],\n",
    "                height,\n",
    "                width,\n",
    "                input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.upsampling:\n",
    "            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\n",
    "                                                       inputs.shape[2] * self.upsampling[1]),\n",
    "                                              align_corners=True)\n",
    "        else:\n",
    "            return K.tf.image.resize_bilinear(inputs, (self.output_size[0],\n",
    "                                                       self.output_size[1]),\n",
    "                                              align_corners=True)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'upsampling': self.upsampling,\n",
    "                  'output_size': self.output_size,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpsampling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
    "    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n",
    "        Implements right \"same\" padding for even kernel sizes\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & poinwise convs\n",
    "            epsilon: epsilon to use in BN layer\n",
    "    \"\"\"\n",
    "\n",
    "    if stride == 1:\n",
    "        depth_padding = 'same'\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        depth_padding = 'valid'\n",
    "\n",
    "    if not depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
    "                        padding=depth_padding, use_bias=False)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n",
    "    \"\"\"Implements right 'same' padding for even kernel sizes\n",
    "        Without this there is a 1 pixel drift when stride = 2\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "    \"\"\"\n",
    "    if stride == 1:\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='same', use_bias=False,\n",
    "                      dilation_rate=(rate, rate)\n",
    "                      )(x)\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='valid', use_bias=False,\n",
    "                      dilation_rate=(rate, rate)\n",
    "                      )(x)\n",
    "\n",
    "\n",
    "def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n",
    "                    rate=1, depth_activation=False, return_skip=False):\n",
    "    \"\"\" Basic building block of modified Xception network\n",
    "        Args:\n",
    "            inputs: input tensor\n",
    "            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n",
    "            prefix: prefix before name\n",
    "            skip_connection_type: one of {'conv','sum','none'}\n",
    "            stride: stride at last depthwise conv\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & pointwise convs\n",
    "            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n",
    "            \"\"\"\n",
    "    residual = inputs\n",
    "    for i in range(3):\n",
    "        residual = SepConv_BN(residual,\n",
    "                              depth_list[i],\n",
    "                              prefix + '_separable_conv{}'.format(i + 1),\n",
    "                              stride=stride if i == 2 else 1,\n",
    "                              rate=rate,\n",
    "                              depth_activation=depth_activation)\n",
    "        if i == 1:\n",
    "            skip = residual\n",
    "    if skip_connection_type == 'conv':\n",
    "        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n",
    "                                kernel_size=1,\n",
    "                                stride=stride)\n",
    "        outputs = layers.add([residual, shortcut])\n",
    "    elif skip_connection_type == 'sum':\n",
    "        outputs = layers.add([residual, inputs])\n",
    "    elif skip_connection_type == 'none':\n",
    "        outputs = residual\n",
    "    if return_skip:\n",
    "        return outputs, skip\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n",
    "    in_channels = inputs._keras_shape[-1]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'expanded_conv_{}_'.format(block_id)\n",
    "    if block_id:\n",
    "        # Expand\n",
    "\n",
    "        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n",
    "                   use_bias=False, activation=None)(x)\n",
    "        x = Activation(relu6)(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "    # Depthwise\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n",
    "                        use_bias=False, padding='same', dilation_rate=(rate, rate))(x)\n",
    "\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    # Project\n",
    "    x = Conv2D(pointwise_filters,\n",
    "               kernel_size=1, padding='same', use_bias=False, activation=None)(x)\n",
    "\n",
    "    if skip_connection:\n",
    "        return Add()([inputs, x])\n",
    "\n",
    "    # if in_channels == pointwise_filters and stride == 1:\n",
    "    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2():\n",
    "\n",
    "    input_shape = (RESIZE,RESIZE,3)\n",
    "    alpha=1.\n",
    "    img_input = Input(shape=input_shape)\n",
    "    y_full = Input(shape=(RESIZE,RESIZE,CLASSES))\n",
    "    y_input= Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(y_full)[0] \n",
    "    \n",
    "    # A network that takes as input the given image and outputs the \n",
    "    # parameters to multinomial distributions for each pixel\n",
    "    # i.e. a mask.\n",
    "    # This network is refered to as q(y|x) in the paper\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    y = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(img_input)\n",
    "    y = Activation(relu6)(y)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(y)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(y)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    y = Concatenate()([b4, b0])\n",
    "\n",
    "    y = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0 )(y)\n",
    "    \n",
    "    y = Conv2D(CLASSES, (1, 1), padding='same')(y)\n",
    "    y = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(y)\n",
    "    \n",
    "    # This is the predicted mask for each image\n",
    "    y_output = Activation('softmax',name = 'q_y')(y)\n",
    "    \n",
    "    # Splits out the masks that have a true mask(y_sup) and those that don't(y_un)\n",
    "    y_sup,y_un =Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(y_output) \n",
    "\n",
    "    # A function that generates samples from a set of mulitnomial distributions \n",
    "    # in a way that the gradient can propagate through.\n",
    "    def gumbel_softmax(args):\n",
    "        ind_multinomial = args\n",
    "        gumbel_dist = tfp.distributions.RelaxedOneHotCategorical(TEMPERATURE, probs=ind_multinomial)\n",
    "        return gumbel_dist.sample()\n",
    "    \n",
    "    # Samples from the \"distribution\" of the masks for the images without labels\n",
    "    y_un_sample = Lambda(gumbel_softmax)(y_un)\n",
    "    \n",
    "    # Replaces the predicted masks for the images with labels with the true masks\n",
    "    # this may seem wierd but it is what is mathematiclly correct\n",
    "    y_t_un = Concatenate(axis=0)([y_input,y_un_sample])\n",
    "\n",
    "    # END q(y|x)\n",
    "    \n",
    "    # A network that takes as input the half true half predicted masks as\n",
    "    # well as the images as input and outputs the parameters to\n",
    "    # a set of multivariate gaussian distributions\n",
    "    # This network is refered to as q(z|y,x) in the paper\n",
    "    ys = Concatenate(axis=-1)([y_t_un,img_input])\n",
    "\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(ys)\n",
    "\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(x)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    # A log(sigma) for each latent variable\n",
    "    # Note that the choices of CLASSES as the width of this output\n",
    "    # is somewhat arbitrary\n",
    "    # Note that log(sigma) instead of sigma or sigma^2 is chosen as the output for numericle stability\n",
    "    z_log_var = Conv2D(CLASSES, (1, 1), padding='same')(x)\n",
    "    z_log_var = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(z_log_var)\n",
    "    \n",
    "    # A mean for each latent variable\n",
    "    z_mean = Conv2D(CLASSES, (1, 1), padding='same')(x)\n",
    "    z_mean = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(z_mean)\n",
    "\n",
    "    \n",
    "    # A function for sampling from the above gaussian distrubution\n",
    "    def gaussian_sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "        z_sample = z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "        return z_sample\n",
    "    \n",
    "    # Samples form the predicted gaussian distribution\n",
    "    z_sample = Lambda(gaussian_sampling,name = 'q_z')([z_mean, z_log_var])\n",
    "    \n",
    "    # END q(z|x,y)\n",
    "    \n",
    "    # A network that takes as input the above z sample and the\n",
    "    # half true half predicted y and outputs the parameters to\n",
    "    # a bernoulli distribution for each pixel and channel.\n",
    "    # This could be interpruted as an image.\n",
    "    # This is refered to as p(x|y,z) in the paper.\n",
    "    x = Concatenate()([z_sample,y_t_un])\n",
    " \n",
    "    input_shape = (RESIZE,RESIZE,CLASSES + CLASSES)\n",
    "\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(x)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    # DeepLab v.3+ decoder\n",
    "\n",
    "    x = Conv2D(3, (1, 1), padding='same')(x)\n",
    "    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n",
    "\n",
    "    x = Activation('sigmoid',name = 'p_x')(x)\n",
    "\n",
    "    # END p(x|y,z)\n",
    "    \n",
    "    \n",
    "    # A function that calcuates the intersection over union couf.\n",
    "    def iou_coef(y_true, y_pred, smooth=1):\n",
    "        intersection = K.sum(K.abs(y_input * y_sup), axis=[1,2,3])\n",
    "        union = K.sum(y_input,[1,2,3])+K.sum(y_sup,[1,2,3])-intersection\n",
    "        iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "        return iou\n",
    "    \n",
    "    # Calculates the log liklihood of a point x under a gaussian distribution parameterized by mu and log_var\n",
    "    def gaussian_ll(args):\n",
    "        x , mu, log_var = args\n",
    "        x = Flatten()(x)\n",
    "        mu = Flatten()(mu)\n",
    "        log_var = Flatten()(log_var)\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - log_var/2 - ((x - mu)/(2*K.exp(log_var) + 1e-8))*(x - mu)\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "    \n",
    "    # Calculates the log liklihood of a point x under a unit gaussian distribution\n",
    "    def unit_gaussian_ll(args):\n",
    "        x = args\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - x**2/2\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "\n",
    "    \n",
    "    # Calculates the log liklihood that the sampled 'z' is under the unit gaussian distributions \n",
    "    def log_pz(y_true,y_pred):\n",
    "        loss = unit_gaussian_ll(z_sample)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    # Calculates the log liklihood that the sampled 'z' is under the gaussian distributions predicted by\n",
    "    # q(z|y,x)\n",
    "    def log_qz(y_true,y_pred):\n",
    "        loss = gaussian_ll([z_sample,z_mean,z_log_var])\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the log liklihood that the all possible 'y' is under y's true distribution WHICH\n",
    "    # IS ASSUMED TO BE BERNOULLI WITH CONSTANT PROBABILITY 1/CLASSES FOR ALL Y\n",
    "    def log_py(y_true,y_pred):\n",
    "        y = Flatten()(y_t_un)\n",
    "        ones = K.ones_like(y)/CLASSES\n",
    "        loss = -K.binary_crossentropy(ones,y)\n",
    "        loss = K.sum(loss,axis=1)\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the log liklihood that the true images is predicted by\n",
    "    # p(x|y,z). Image is expected to be binarized.\n",
    "    def log_px(y_true,y_pred):\n",
    "        #Effectivly calculates\n",
    "        #if(img_input == 1)\n",
    "        #  loss = log(x)\n",
    "        #else if(img_input == 0)\n",
    "        #  loss = log(1 - x)\n",
    "        loss = -K.binary_crossentropy(img_input,x)\n",
    "        loss = K.sum(loss,axis = 1)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    # Calculates the log liklihood that the sampled y is under the predicted y's distribution WHICH\n",
    "    # IS ASSUMED TO BE BERNOULLI\n",
    "    def log_qy(y_true,y_pred):\n",
    "        zero = K.zeros(shape = ((BATCH_SIZE//2)))\n",
    "        un = -K.binary_crossentropy(Flatten()(y_un),Flatten()(y_un_sample))\n",
    "        un = K.sum(un,axis = 1)\n",
    "        loss = K.concatenate([zero,un])\n",
    "        return loss\n",
    "       \n",
    "    \n",
    "    # Calculates a supervised loss for the y predictions for the images that we have labels for\n",
    "    def y_class(y_true,y_pred):\n",
    "        zero = K.zeros(shape = (BATCH_SIZE//2))\n",
    "        sup_loss = K.binary_crossentropy(Flatten()(y_input),Flatten()(y_sup))\n",
    "        sup_loss = K.sum(sup_loss,axis = 1)\n",
    "        loss = K.concatenate([sup_loss,zero])\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the negative lower bounds(i.e. the minamization target) for q(y|x),q(z|x,y) and p(x|z,y)\n",
    "    def y_loss(y_true,y_pred):\n",
    "        return K.mean(1*log_qy(y_true,y_pred) + -1*log_py(y_true,y_pred) + 1000*y_class(y_true,y_pred))\n",
    "    \n",
    "    def z_loss(y_true,y_pred):\n",
    "        return K.mean(log_qz(y_true,y_pred) + -1*log_pz(y_true,y_pred))\n",
    "    \n",
    "    def x_loss(y_true,y_pred):\n",
    "        return K.mean(-log_px(y_true,y_pred))\n",
    "    \n",
    "    \n",
    "    loss = {'p_x':x_loss,'q_z':z_loss,'q_y':y_loss}\n",
    "    metrics = {'q_y':iou_coef}\n",
    "    model = Model([img_input,y_full], [x,y_output,z_sample], name = 'VAE')\n",
    "    model.compile(loss = loss,metrics = metrics,optimizer = keras.optimizers.Adam(lr=.1,clipnorm = 1.,clipvalue = 0.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pascal_voc_m2_vae = M2()\n",
    "pascal_voc_m2_vae.load_weights('Pascal_Voc_M2_VAE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of image: i.e. the image will be RESIZE X RESIZE\n",
    "RESIZE = 128\n",
    "#Number of possible classes for each pixel\n",
    "CLASSES = 21\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, backbone='mobilenetv2', OS=16, alpha=1.):\n",
    "    \"\"\" Instantiates the Deeplabv3+ architecture\n",
    "\n",
    "    Optionally loads weights pre-trained\n",
    "    on PASCAL VOC. This model is available for TensorFlow only,\n",
    "    and can only be used with inputs following the TensorFlow\n",
    "    data format `(width, height, channels)`.\n",
    "    # Arguments\n",
    "        weights: one of 'pascal_voc' (pre-trained on pascal voc)\n",
    "            or None (random initialization)\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: shape of input image. format HxWxC\n",
    "            PASCAL VOC model was trained on (512,512,3) images\n",
    "        classes: number of desired classes. If classes != 21,\n",
    "            last layer is initialized randomly\n",
    "        backbone: backbone to use. one of {'xception','mobilenetv2'}\n",
    "        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}.\n",
    "            Used only for xception backbone.\n",
    "        alpha: controls the width of the MobileNetV2 network. This is known as the\n",
    "            width multiplier in the MobileNetV2 paper.\n",
    "                - If `alpha` < 1.0, proportionally decreases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` > 1.0, proportionally increases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` = 1, default number of filters from the paper\n",
    "                    are used at each layer.\n",
    "            Used only for mobilenetv2 backbone\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "\n",
    "    # Raises\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "        ValueError: in case of invalid argument for `weights` or `backbone`\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if not (weights in {'pascal_voc', None}):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `pascal_voc` '\n",
    "                         '(pre-trained on PASCAL VOC)')\n",
    "\n",
    "    if K.backend() != 'tensorflow':\n",
    "        raise RuntimeError('The Deeplabv3+ model is only available with '\n",
    "                           'the TensorFlow backend.')\n",
    "\n",
    "    if not (backbone in {'xception', 'mobilenetv2'}):\n",
    "        raise ValueError('The `backbone` argument should be either '\n",
    "                         '`xception`  or `mobilenetv2` ')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        if OS == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2  # ! Not mentioned in paper, but required\n",
    "            exit_block_rates = (2, 4)\n",
    "            atrous_rates = (12, 24, 36)\n",
    "        else:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "            atrous_rates = (6, 12, 18)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), strides=(2, 2),\n",
    "                   name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = _conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "        x = _xception_block(x, [128, 128, 128], 'entry_flow_block1',\n",
    "                            skip_connection_type='conv', stride=2,\n",
    "                            depth_activation=False)\n",
    "        x, skip1 = _xception_block(x, [256, 256, 256], 'entry_flow_block2',\n",
    "                                   skip_connection_type='conv', stride=2,\n",
    "                                   depth_activation=False, return_skip=True)\n",
    "\n",
    "        x = _xception_block(x, [728, 728, 728], 'entry_flow_block3',\n",
    "                            skip_connection_type='conv', stride=entry_block3_stride,\n",
    "                            depth_activation=False)\n",
    "        for i in range(16):\n",
    "            x = _xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n",
    "                                skip_connection_type='sum', stride=1, rate=middle_block_rate,\n",
    "                                depth_activation=False)\n",
    "\n",
    "        x = _xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n",
    "                            skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n",
    "                            depth_activation=False)\n",
    "        x = _xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n",
    "                            skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n",
    "                            depth_activation=True)\n",
    "\n",
    "    else:\n",
    "        OS = 8\n",
    "        first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "        x = Conv2D(first_block_filters,\n",
    "                   kernel_size=3,\n",
    "                   strides=(2, 2), padding='same',\n",
    "                   use_bias=False, name='Conv')(img_input)\n",
    "        x = Activation(relu6, name='Conv_Relu6')(x)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                                expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=1, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=3, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=4, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "        # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                                expansion=6, block_id=6, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=7, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=8, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=10, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=11, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                                expansion=6, block_id=13, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=14, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False, name='image_pooling')(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n",
    "    b0 = Activation('relu', name='aspp0_activation')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "    if backbone == 'xception':\n",
    "        # rate = 6 (12)\n",
    "        b1 = SepConv_BN(x, 256, 'aspp1',\n",
    "                        rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 12 (24)\n",
    "        b2 = SepConv_BN(x, 256, 'aspp2',\n",
    "                        rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 18 (36)\n",
    "        b3 = SepConv_BN(x, 256, 'aspp3',\n",
    "                        rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "        # concatenate ASPP branches & project\n",
    "        x = Concatenate()([b4, b0, b1, b2, b3])\n",
    "    else:\n",
    "        x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False, name='concat_projection')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # DeepLab v.3+ decoder\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        # Feature projection\n",
    "        # x4 (x2) block\n",
    "        x = BilinearUpsampling(output_size=(int(np.ceil(input_shape[0] / 4)),\n",
    "                                            int(np.ceil(input_shape[1] / 4))))(x)\n",
    "        dec_skip1 = Conv2D(48, (1, 1), padding='same',\n",
    "                           use_bias=False, name='feature_projection0')(skip1)\n",
    "        dec_skip1 = Activation('relu')(dec_skip1)\n",
    "        x = Concatenate()([x, dec_skip1])\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv0',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv1',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "    # you can use it with arbitary number of classes\n",
    "    if classes == 21:\n",
    "        last_layer_name = 'logits_semantic'\n",
    "    else:\n",
    "        last_layer_name = 'custom_logits_semantic'\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n",
    "    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n",
    "    x = keras.layers.Activation('softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    model = Model(inputs, x, name='deeplabv3+')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    if weights == 'pascal_voc':\n",
    "        if backbone == 'xception':\n",
    "            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_X,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_MOBILE,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_input(x):\n",
    "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
    "    # Arguments\n",
    "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
    "    # Returns\n",
    "        Input array scaled to [-1.,1.]\n",
    "    \"\"\"\n",
    "    return imagenet_utils.preprocess_input(x, mode='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the intersection over union coef between two masks\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "  intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "  union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "  iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "  return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_baseline = Deeplabv3(input_shape=(RESIZE,RESIZE,3),weights = None, classes=CLASSES)\n",
    "pascal_voc_baseline.compile(optimizer = keras.optimizers.Adam(lr=.1,clipnorm = 1.,clipvalue = .5), loss = 'binary_crossentropy',metrics = [iou_coef])\n",
    "pascal_voc_baseline.load_weights('Pascal_Voc_Baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the augmentitations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.Flip(p=0.5),\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),     \n",
    "        A.Resize(height = RESIZE, width = RESIZE, interpolation=1, always_apply=True, p=1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),\n",
    "        A.Resize(height = RESIZE, width = RESIZE, interpolation=1, always_apply=True, p=1)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for validation\n",
    "class MNISTValGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in the labeled images\n",
    "    def __init__(self,batch_size = 64):\n",
    "        \n",
    "        self.labeled_images = read_csv(\"./MNIST/59900_100_balenced/val_x.csv\").to_numpy()\n",
    "        self.labels = read_csv(\"./MNIST/59900_100_balenced/val_y.csv\").to_numpy()\n",
    "        \n",
    "        self.labeled_index = np.arange(0, len(self.labeled_images), 1).tolist()\n",
    "        random.shuffle(self.labeled_index)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.X = np.zeros((self.batch_size, 28*28), dtype='float32')\n",
    "        self.Y = np.zeros((self.batch_size,10), dtype='float32')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return  len(self.labeled_index) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        for x in self.labeled_index[i*self.batch_size : (i+1)*self.batch_size]:\n",
    "            \n",
    "            image = self.labeled_images[x] + .5\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "            label = self.labels[x]\n",
    "\n",
    "            self.X[n] = image\n",
    "            self.Y[n] = label\n",
    "            n = n + 1\n",
    "            \n",
    "        return self.X, self.Y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_baseline_val_gen = MNISTValGenerator(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for validation\n",
    "class ValGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in the labeled images\n",
    "    def __init__(self,batch_size = 64):\n",
    "        \n",
    "        self.labeled_images = read_csv(\"./MNIST/59900_100_balenced/val_x.csv\").to_numpy()\n",
    "        self.labels = read_csv(\"./MNIST/59900_100_balenced/val_y.csv\").to_numpy()\n",
    "        \n",
    "        self.labeled_index = np.arange(0, len(self.labeled_images), 1).tolist()\n",
    "        random.shuffle(self.labeled_index)\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.X = np.zeros((self.batch_size*2, 28*28), dtype='float32')\n",
    "        self.Y = np.zeros((self.batch_size*2,10), dtype='float32')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return  len(self.labeled_index) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        for x in self.labeled_index[i*self.batch_size : (i+1)*self.batch_size]:\n",
    "            \n",
    "            image = self.labeled_images[x] + .5\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "            label = self.labels[x]\n",
    "\n",
    "            self.X[n] = image\n",
    "            self.Y[n] = label\n",
    "            n = n + 1\n",
    "            \n",
    "        return [self.X, self.Y], [self.Y,self.Y,self.Y]\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_m2_vae_val_gen = ValGenerator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for validation\n",
    "class ValGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in the labeled images\n",
    "    def __init__(self,  n_classes=21, batch_size=32, resize_shape=(128,128)):\n",
    "            \n",
    "        self.image_path_list = os.listdir('./VOCdevkit/VOC2012/val_frames/')\n",
    "        random.shuffle(self.image_path_list)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.resize_shape = resize_shape\n",
    "        if self.resize_shape:\n",
    "            self.X = np.zeros((self.batch_size, resize_shape[1], resize_shape[0], 3), dtype='float32')\n",
    "            self.Y = np.zeros((self.batch_size, resize_shape[1],resize_shape[0],n_classes), dtype='float32')\n",
    "        else:\n",
    "            raise Exception('No image dimensions specified!')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        \n",
    "        for x in self.image_path_list[i*self.batch_size:(i+1)*self.batch_size]:\n",
    "            \n",
    "            image = np.array(Image.open('./VOCdevkit/VOC2012/val_frames/' + x))\n",
    "            label = np.array(Image.open('./VOCdevkit/VOC2012/val_masks/' + x.replace('.jpg','.png')))\n",
    "\n",
    "            sample = get_validation_augmentation()(image=image, mask=label)\n",
    "            image, label = sample['image']/255, sample['mask']\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "\n",
    "            categorical_label = keras.utils.to_categorical(label)\n",
    "\n",
    "            self.X[n] = image\n",
    "            #cat_label -> image\n",
    "            self.Y[n] = categorical_label[:,:,0:21]\n",
    "            n = n + 1\n",
    "\n",
    "        return self.X, self.Y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.image_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_baseline_val_gen = ValGenerator(batch_size=8,n_classes = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for validation\n",
    "class ValGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in the labeled images\n",
    "    def __init__(self,  n_classes=21, batch_size=32, resize_shape=(128,128)):\n",
    "            \n",
    "        self.image_path_list = os.listdir('./VOCdevkit/VOC2012/val_frames/')\n",
    "        random.shuffle(self.image_path_list)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = int(batch_size/2)\n",
    "        self.resize_shape = resize_shape\n",
    "        if self.resize_shape:\n",
    "            self.X = np.zeros((self.batch_size*2, resize_shape[1], resize_shape[0], 3), dtype='float32')\n",
    "            self.Y = np.zeros((self.batch_size*2, resize_shape[1],resize_shape[0],n_classes), dtype='float32')\n",
    "        else:\n",
    "            raise Exception('No image dimensions specified!')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        \n",
    "        for x in self.image_path_list[i*self.batch_size:(i+1)*self.batch_size]:\n",
    "            \n",
    "            image = np.array(Image.open('./VOCdevkit/VOC2012/val_frames/' + x))\n",
    "            label = np.array(Image.open('./VOCdevkit/VOC2012/val_masks/' + x.replace('.jpg','.png')))\n",
    "\n",
    "            sample = get_validation_augmentation()(image=image, mask=label)\n",
    "            image, label = sample['image']/255, sample['mask']\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "\n",
    "            categorical_label = keras.utils.to_categorical(label)\n",
    "\n",
    "            self.X[n] = image\n",
    "            #cat_label -> image\n",
    "            self.Y[n] = categorical_label[:,:,0:21]\n",
    "            n = n + 1\n",
    "\n",
    "        return [self.X, self.Y] , [self.Y,self.Y,self.Y]\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.image_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_m2_vae_val_gen = ValGenerator(batch_size = 16,n_classes = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def display_images(arr):\n",
    "    n = len(arr) \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(arr[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def display_rgb_image(image): \n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNIST Baseline\n",
      "\n",
      "Accuracy: 0.7399000012874604\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAABwCAYAAACkaY2RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAHX0lEQVR4nO3dQXLbOBAFUGkqV5j13P9Ys88dOItUJi5bpEAYJD6A91apxFJUaDYpd3UDz23bHgAAAABk+av3BwAAAADgK0UbAAAAgECKNgAAAACBFG0AAAAAAinaAAAAAARStAEAAAAI9OPMDz+fT+eDd7Jt27PF+4hhVz+3bfu7xRuJYz9ycQpycQJycQpycQJycQpycQJycQovc1GnDdzn394fAHg8HnIRUshFyCAXIcPLXFS0AQAAAAikaAMAAAAQSNEGAAAAIJCiDQAAAEAgRRsAAACAQIo2AAAAAIEUbQAAAAAC/ej9AQD2bNv2/5+fz2fHT0IL4gl1PubOneQpAOmOvl8ePT9HesbptAEAAAAIpGgDAAAAEEjRBgAAACCQPW2IVjrHP9JMIvt67dvAdfZi+vnv5TD8kXIvlKcAJCr9fjkLnTYAAAAAgRRtAAAAAAItMx51plVK+y/cZ9Y2RoDR+T4ErOzoKOm9nzvinlqv9veFWdZcpw0AAABAIEUbAAAAgEDLjEedUdoKx/U+rn9tW5x4Qh65mE2rd5Yr1/ko1k6PyrMXL7Fpp/XY9ufY+F46phbXxdF7uBa+8l3kD502AAAAAIEUbQAAAAACKdoAAAAABFpmT5sWx7Rxvxb72ADXkm/jEKsxrDCfv7rWuWivjPeO9pK58t54Zt+oj8Stv9K9NWt/zxTjr+xj85pOGwAAAIBAijYAAAAAgZYZj/pMi/j4jtriWhwVDpRp0T5MO3fe8xwJPb47x0RWYy37ShlLOrpPukbGUXtdHMXb8e+U0mkDAAAAEEjRBgAAACCQog0AAABAoGX3tGFuZkRzmd8enxjmufqITDGfi3heJ3Ft7T311Z1rYL3h+1bPI502AAAAAIEUbQAAAAACGY96YfX2q972WovFZVyJ7eKcUxtDeXudK/NKzs7n6hG6lbTOj7uPXZ9thHzka9vx32tLvCbJpNMGAAAAIJCiDQAAAECgZcajtBzO7Si+s7UBj0LOzUULd38jjKi53+aQp30c3SvlBLVGHgEDvk+nDQAAAEAgRRsAAACAQIo2AAAAAIGW2dPm7uMUae9oNlx889gDBfrouaeB/RTu1eLeKmZlSte6dF8nz8V2Zvm+UZuLcjjbyNdkD3v5vPoeYTptAAAAAAIp2gAAAAAEmno8SjvamPba4rSNwr1q7qHybVyemdBWSk65L48p5frhvdLfV+Tie3vX/eprp9MGAAAAIJCiDQAAAECgqcejSneTX73dqjftn3MSV2jLKXnrMqrIWeL/VYuR+xSjf/6ViBUt6LQBAAAACKRoAwAAABBI0QYAAAAg0NR72tjHZnyO+R6H/TXgWq1zrMX7uddew/2Us+TiL6X7WX7+t4T1k/d91O51NNMeSUn2crhFzh69R3rdQKcNAAAAQCBFGwAAAIBA041HaS2EPlocR5zQfriy2vunuN2jNMeufg6Kdzut75O+A12ntI1+7zVnXlfzmfjq6vVnXL2en9yvdEzy6B6fMAqn0wYAAAAgkKINAAAAQCBFGwAAAIBA0+1pwxjMjPKbmfzxiFmGmj026Mt+Q3OoXecWOSvG9Ur3rNh7zeefq42FPf/aaXGEs+fnmEpzsSZ3jvK+xdHjNXTaAAAAAARStAEAAAAIZDwKaEJ76Zhq4nbmNVq671G6zkYyrnfFvdD6j6nFtSD21yg9Drw0hr4DXefM2tbEq2akCu6m0wYAAAAgkKINAAAAQKAhx6NKW9+0sa2j107eq9MODND+Xnj1M6z01A3ft/qwnverGTF1Gtx8rHmWXqd8Jf5+o9MGAAAAIJCiDQAAAEAgRRsAAACAQEPuaQPv7M0imlXtTwzuN9p+G7C6K46K/u6Rxu/en18S90KgndbXvevlHu5X4zt6ptXuvzZS/um0AQAAAAikaAMAAAAQaJjxKMdOrqN1DF0TwMpq2n/dN8c3Utv36Kw1ZxjhP8e68ErNceAjjwPrtAEAAAAIpGgDAAAAEEjRBgAAACDQMHvaML5eM7wf/9+EmUS4W+kRh/JjbeJ/zmj7mNTM/7smrmNtAdqoeb4dvUcinTYAAAAAgRRtAAAAAALFjkcdtTalty/xWovWtZL35j7WfUziBt83ch6N/NkTjDYaB7CKWZ9vOm0AAAAAAinaAAAAAASKHY9ibrO2rgH0ZnQDrlV6It+718FHn68j1wvwm04bAAAAgECKNgAAAACBFG0AAAAAAsXuaWOOEwCu4zkLbXzMJXtK8Y7rBThLpw0AAABAIEUbAAAAgECx41EAwHnGnqAf+ccZrheghE4bAAAAgECKNgAAAACBFG0AAAAAAinaAAAAAARStAEAAAAIpGgDAAAAEOjskd8/H4/Hv1d8EA790/C9xLAfcRyfGM5BHMcnhnMQx/GJ4RzEcXxiOIeXcXxu23b3BwEAAADgDeNRAAAAAIEUbQAAAAACKdoAAAAABFK0AQAAAAikaAMAAAAQSNEGAAAAIJCiDQAAAEAgRRsAAACAQIo2AAAAAIH+A3e2wbCB26/uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicition: [1 8 1 1 9 2 8 9 2 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMNIST Baseline\\n\")\n",
    "print(\"Accuracy: \" + str(mnist_baseline.evaluate_generator(mnist_baseline_val_gen)[-1]))\n",
    "display_images(mnist_m2_vae_val_gen.__getitem__(0)[0][0][0:10])\n",
    "print(\"Label Predicition: \" + str(np.argmax(mnist_baseline.predict(mnist_m2_vae_val_gen.__getitem__(0)[0][0])[0:10],axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MNIST M2-VAE\n",
      "\n",
      "Accuracy: 0.8551000005751849\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Predicition: [0 6 6 1 2 7 2 7 3 5]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMNIST M2-VAE\\n\")\n",
    "print(\"Accuracy: \" + str(mnist_m2_vae.evaluate_generator(mnist_m2_vae_val_gen)[-1]))\n",
    "display_images(mnist_m2_vae_val_gen.__getitem__(0)[0][0][0:10])\n",
    "print(\"Label Predicition: \" + str(np.argmax(mnist_m2_vae.predict_generator\n",
    "                                            (mnist_m2_vae_val_gen)[1][0:10] ,axis = -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pascal Voc Baseline\n",
      "\n",
      "IOU Coefficient: 0.5451923538367827\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPascal Voc Baseline\\n\")\n",
    "print(\"IOU Coefficient: \" + str(pascal_voc_baseline.evaluate_generator(pascal_voc_baseline_val_gen)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pascal Voc M2-VAE\n",
      "\n",
      "IOU Coefficient: 0.5765758407312435\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPascal Voc M2-VAE\\n\")\n",
    "print(\"IOU Coefficient: \" + str(pascal_voc_m2_vae.evaluate_generator(pascal_voc_m2_vae_val_gen)[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
