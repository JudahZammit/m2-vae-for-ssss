{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M2_VAE for semantic segmentation\n",
    "# A semi-supervised model for semantic segmentation on pascal voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Model,load_model\n",
    "from keras import layers\n",
    "from keras.layers import (Input,Activation,Concatenate,Add,Dropout,BatchNormalization,Conv2D,DepthwiseConv2D\n",
    "                        ,ZeroPadding2D,AveragePooling2D,Lambda,Conv2DTranspose, MaxPooling2D, concatenate\n",
    "                        ,Dropout,UpSampling2D,Flatten)\n",
    "from keras.engine import Layer,InputSpec\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "from random import randint\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                    # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of image: i.e. the image will be RESIZE X RESIZE\n",
    "RESIZE = 128\n",
    "\n",
    "#Number of possible classes for each pixel\n",
    "CLASSES = 21\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Used in the gumbel softmax sampling trick\n",
    "TEMPERATURE = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of this code comes from \n",
    "# https://github.com/bonlime/keras-deeplab-v3-plus/blob/master/model.py\n",
    "# however it has been heavily modified\n",
    "\n",
    "\n",
    "# Functions and layers that are used by the deeplab networks\n",
    "class BilinearUpsampling(Layer):\n",
    "    \"\"\"Just a simple bilinear upsampling layer. Works only with TF.\n",
    "       Args:\n",
    "           upsampling: tuple of 2 numbers > 0. The upsampling ratio for h and w\n",
    "           output_size: used instead of upsampling arg if passed!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, upsampling=(2, 2), output_size=None, data_format=None, **kwargs):\n",
    "\n",
    "        super(BilinearUpsampling, self).__init__(**kwargs)\n",
    "\n",
    "        #self.data_format = K.normalize_data_format(data_format)\n",
    "        self.data_format = None\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "        if output_size:\n",
    "            self.output_size = conv_utils.normalize_tuple(\n",
    "                output_size, 2, 'output_size')\n",
    "            self.upsampling = None\n",
    "        else:\n",
    "            self.output_size = None\n",
    "            self.upsampling = conv_utils.normalize_tuple(\n",
    "                upsampling, 2, 'upsampling')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.upsampling:\n",
    "            height = self.upsampling[0] * \\\n",
    "                input_shape[1] if input_shape[1] is not None else None\n",
    "            width = self.upsampling[1] * \\\n",
    "                input_shape[2] if input_shape[2] is not None else None\n",
    "        else:\n",
    "            height = self.output_size[0]\n",
    "            width = self.output_size[1]\n",
    "        return (input_shape[0],\n",
    "                height,\n",
    "                width,\n",
    "                input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.upsampling:\n",
    "            return K.tf.image.resize_bilinear(inputs, (inputs.shape[1] * self.upsampling[0],\n",
    "                                                       inputs.shape[2] * self.upsampling[1]),\n",
    "                                              align_corners=True)\n",
    "        else:\n",
    "            return K.tf.image.resize_bilinear(inputs, (self.output_size[0],\n",
    "                                                       self.output_size[1]),\n",
    "                                              align_corners=True)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'upsampling': self.upsampling,\n",
    "                  'output_size': self.output_size,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpsampling, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
    "    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n",
    "        Implements right \"same\" padding for even kernel sizes\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & poinwise convs\n",
    "            epsilon: epsilon to use in BN layer\n",
    "    \"\"\"\n",
    "\n",
    "    if stride == 1:\n",
    "        depth_padding = 'same'\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        depth_padding = 'valid'\n",
    "\n",
    "    if not depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
    "                        padding=depth_padding, use_bias=False)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "    x = Conv2D(filters, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "\n",
    "    if depth_activation:\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n",
    "    \"\"\"Implements right 'same' padding for even kernel sizes\n",
    "        Without this there is a 1 pixel drift when stride = 2\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "    \"\"\"\n",
    "    if stride == 1:\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='same', use_bias=False,\n",
    "                      dilation_rate=(rate, rate)\n",
    "                      )(x)\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='valid', use_bias=False,\n",
    "                      dilation_rate=(rate, rate)\n",
    "                      )(x)\n",
    "\n",
    "\n",
    "def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n",
    "                    rate=1, depth_activation=False, return_skip=False):\n",
    "    \"\"\" Basic building block of modified Xception network\n",
    "        Args:\n",
    "            inputs: input tensor\n",
    "            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n",
    "            prefix: prefix before name\n",
    "            skip_connection_type: one of {'conv','sum','none'}\n",
    "            stride: stride at last depthwise conv\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & pointwise convs\n",
    "            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n",
    "            \"\"\"\n",
    "    residual = inputs\n",
    "    for i in range(3):\n",
    "        residual = SepConv_BN(residual,\n",
    "                              depth_list[i],\n",
    "                              prefix + '_separable_conv{}'.format(i + 1),\n",
    "                              stride=stride if i == 2 else 1,\n",
    "                              rate=rate,\n",
    "                              depth_activation=depth_activation)\n",
    "        if i == 1:\n",
    "            skip = residual\n",
    "    if skip_connection_type == 'conv':\n",
    "        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n",
    "                                kernel_size=1,\n",
    "                                stride=stride)\n",
    "        outputs = layers.add([residual, shortcut])\n",
    "    elif skip_connection_type == 'sum':\n",
    "        outputs = layers.add([residual, inputs])\n",
    "    elif skip_connection_type == 'none':\n",
    "        outputs = residual\n",
    "    if return_skip:\n",
    "        return outputs, skip\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n",
    "    in_channels = inputs._keras_shape[-1]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'expanded_conv_{}_'.format(block_id)\n",
    "    if block_id:\n",
    "        # Expand\n",
    "\n",
    "        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n",
    "                   use_bias=False, activation=None)(x)\n",
    "        x = Activation(relu6)(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "    # Depthwise\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,\n",
    "                        use_bias=False, padding='same', dilation_rate=(rate, rate))(x)\n",
    "\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    # Project\n",
    "    x = Conv2D(pointwise_filters,\n",
    "               kernel_size=1, padding='same', use_bias=False, activation=None)(x)\n",
    "\n",
    "    if skip_connection:\n",
    "        return Add()([inputs, x])\n",
    "\n",
    "    # if in_channels == pointwise_filters and stride == 1:\n",
    "    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2():\n",
    "\n",
    "    input_shape = (RESIZE,RESIZE,3)\n",
    "    alpha=1.\n",
    "    img_input = Input(shape=input_shape)\n",
    "    y_full = Input(shape=(RESIZE,RESIZE,CLASSES))\n",
    "    y_input= Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(y_full)[0] \n",
    "    \n",
    "    # A network that takes as input the given image and outputs the \n",
    "    # parameters to multinomial distributions for each pixel\n",
    "    # i.e. a mask.\n",
    "    # This network is refered to as q(y|x) in the paper\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    y = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(img_input)\n",
    "    y = Activation(relu6)(y)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    y = _inverted_res_block(y, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    y = _inverted_res_block(y, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(y)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(y)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    y = Concatenate()([b4, b0])\n",
    "\n",
    "    y = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0 )(y)\n",
    "    \n",
    "    y = Conv2D(CLASSES, (1, 1), padding='same')(y)\n",
    "    y = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(y)\n",
    "    \n",
    "    # This is the predicted mask for each image\n",
    "    y_output = Activation('softmax',name = 'q_y')(y)\n",
    "    \n",
    "    # Splits out the masks that have a true mask(y_sup) and those that don't(y_un)\n",
    "    y_sup,y_un =Lambda(lambda x:  tf.split(x,num_or_size_splits=2,axis=0))(y_output) \n",
    "\n",
    "    # A function that generates samples from a set of mulitnomial distributions \n",
    "    # in a way that the gradient can propagate through.\n",
    "    def gumbel_softmax(args):\n",
    "        ind_multinomial = args\n",
    "        gumbel_dist = tfp.distributions.RelaxedOneHotCategorical(TEMPERATURE, probs=ind_multinomial)\n",
    "        return gumbel_dist.sample()\n",
    "    \n",
    "    # Samples from the \"distribution\" of the masks for the images without labels\n",
    "    y_un_sample = Lambda(gumbel_softmax)(y_un)\n",
    "    \n",
    "    # Replaces the predicted masks for the images with labels with the true masks\n",
    "    # this may seem wierd but it is what is mathematiclly correct\n",
    "    y_t_un = Concatenate(axis=0)([y_input,y_un_sample])\n",
    "\n",
    "    # END q(y|x)\n",
    "    \n",
    "    # A network that takes as input the half true half predicted masks as\n",
    "    # well as the images as input and outputs the parameters to\n",
    "    # a set of multivariate gaussian distributions\n",
    "    # This network is refered to as q(z|y,x) in the paper\n",
    "    ys = Concatenate(axis=-1)([y_t_un,img_input])\n",
    "\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(ys)\n",
    "\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(x)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    # A log(sigma) for each latent variable\n",
    "    # Note that the choices of CLASSES as the width of this output\n",
    "    # is somewhat arbitrary\n",
    "    # Note that log(sigma) instead of sigma or sigma^2 is chosen as the output for numericle stability\n",
    "    z_log_var = Conv2D(CLASSES, (1, 1), padding='same')(x)\n",
    "    z_log_var = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(z_log_var)\n",
    "    \n",
    "    # A mean for each latent variable\n",
    "    z_mean = Conv2D(CLASSES, (1, 1), padding='same')(x)\n",
    "    z_mean = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(z_mean)\n",
    "\n",
    "    \n",
    "    # A function for sampling from the above gaussian distrubution\n",
    "    def gaussian_sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=K.shape(z_mean))\n",
    "        z_sample = z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "        return z_sample\n",
    "    \n",
    "    # Samples form the predicted gaussian distribution\n",
    "    z_sample = Lambda(gaussian_sampling,name = 'q_z')([z_mean, z_log_var])\n",
    "    \n",
    "    # END q(z|x,y)\n",
    "    \n",
    "    # A network that takes as input the above z sample and the\n",
    "    # half true half predicted y and outputs the parameters to\n",
    "    # a bernoulli distribution for each pixel and channel.\n",
    "    # This could be interpruted as an image.\n",
    "    # This is refered to as p(x|y,z) in the paper.\n",
    "    x = Concatenate()([z_sample,y_t_un])\n",
    " \n",
    "    input_shape = (RESIZE,RESIZE,CLASSES + CLASSES)\n",
    "\n",
    "    OS = 8\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = Conv2D(first_block_filters,\n",
    "               kernel_size=3,\n",
    "               strides=(2, 2), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "    # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                            expansion=6, block_id=6, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=7, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=8, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=10, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=11, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                            expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                            expansion=6, block_id=13, skip_connection=False)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=14, skip_connection=True)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                            expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    #out_shape = int(np.ceil(input_shape[0] / OS))\n",
    "    b4 = AveragePooling2D(pool_size=(int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(x)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False)(b4)\n",
    "    b4 = Activation('relu')(b4)\n",
    "    b4 = BilinearUpsampling((int(np.ceil(input_shape[0] / OS)), int(np.ceil(input_shape[1] / OS))))(b4)\n",
    "\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False)(x)\n",
    "    b0 = Activation('relu')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "\n",
    "    x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0)(x)\n",
    "\n",
    "    # DeepLab v.3+ decoder\n",
    "\n",
    "    x = Conv2D(3, (1, 1), padding='same')(x)\n",
    "    x = BilinearUpsampling(output_size=(input_shape[0], input_shape[1]))(x)\n",
    "\n",
    "    x = Activation('sigmoid',name = 'p_x')(x)\n",
    "\n",
    "    # END p(x|y,z)\n",
    "    \n",
    "    \n",
    "    # A function that calcuates the intersection over union couf.\n",
    "    def iou_coef(y_true, y_pred, smooth=1):\n",
    "        intersection = K.sum(K.abs(y_input * y_sup), axis=[1,2,3])\n",
    "        union = K.sum(y_input,[1,2,3])+K.sum(y_sup,[1,2,3])-intersection\n",
    "        iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "        return iou\n",
    "    \n",
    "    # Calculates the log liklihood of a point x under a gaussian distribution parameterized by mu and log_var\n",
    "    def gaussian_ll(args):\n",
    "        x , mu, log_var = args\n",
    "        x = Flatten()(x)\n",
    "        mu = Flatten()(mu)\n",
    "        log_var = Flatten()(log_var)\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - log_var/2 - ((x - mu)/(2*K.exp(log_var) + 1e-8))*(x - mu)\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "    \n",
    "    # Calculates the log liklihood of a point x under a unit gaussian distribution\n",
    "    def unit_gaussian_ll(args):\n",
    "        x = args\n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        c = -.5 * math.log(2*math.pi)\n",
    "        density = c - x**2/2\n",
    "\n",
    "        return K.sum(density,axis = -1)\n",
    "\n",
    "    \n",
    "    # Calculates the log liklihood that the sampled 'z' is under the unit gaussian distributions \n",
    "    def log_pz(y_true,y_pred):\n",
    "        loss = unit_gaussian_ll(z_sample)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    # Calculates the log liklihood that the sampled 'z' is under the gaussian distributions predicted by\n",
    "    # q(z|y,x)\n",
    "    def log_qz(y_true,y_pred):\n",
    "        loss = gaussian_ll([z_sample,z_mean,z_log_var])\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the log liklihood that the all possible 'y' is under y's true distribution WHICH\n",
    "    # IS ASSUMED TO BE BERNOULLI WITH CONSTANT PROBABILITY 1/CLASSES FOR ALL Y\n",
    "    def log_py(y_true,y_pred):\n",
    "        y = Flatten()(y_t_un)\n",
    "        ones = K.ones_like(y)/CLASSES\n",
    "        loss = -K.binary_crossentropy(ones,y)\n",
    "        loss = K.sum(loss,axis=1)\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the log liklihood that the true images is predicted by\n",
    "    # p(x|y,z). Image is expected to be binarized.\n",
    "    def log_px(y_true,y_pred):\n",
    "        #Effectivly calculates\n",
    "        #if(img_input == 1)\n",
    "        #  loss = log(x)\n",
    "        #else if(img_input == 0)\n",
    "        #  loss = log(1 - x)\n",
    "        loss = -K.binary_crossentropy(img_input,x)\n",
    "        loss = K.sum(loss,axis = 1)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    # Calculates the log liklihood that the sampled y is under the predicted y's distribution WHICH\n",
    "    # IS ASSUMED TO BE BERNOULLI\n",
    "    def log_qy(y_true,y_pred):\n",
    "        zero = K.zeros(shape = ((BATCH_SIZE//2)))\n",
    "        un = -K.binary_crossentropy(Flatten()(y_un),Flatten()(y_un_sample))\n",
    "        un = K.sum(un,axis = 1)\n",
    "        loss = K.concatenate([zero,un])\n",
    "        return loss\n",
    "       \n",
    "    \n",
    "    # Calculates a supervised loss for the y predictions for the images that we have labels for\n",
    "    def y_class(y_true,y_pred):\n",
    "        zero = K.zeros(shape = (BATCH_SIZE//2))\n",
    "        sup_loss = K.binary_crossentropy(Flatten()(y_input),Flatten()(y_sup))\n",
    "        sup_loss = K.sum(sup_loss,axis = 1)\n",
    "        loss = K.concatenate([sup_loss,zero])\n",
    "        return loss\n",
    "    \n",
    "    # Calculates the negative lower bounds(i.e. the minamization target) for q(y|x),q(z|x,y) and p(x|z,y)\n",
    "    def y_loss(y_true,y_pred):\n",
    "        return K.mean(1*log_qy(y_true,y_pred) + -1*log_py(y_true,y_pred) + 1000*y_class(y_true,y_pred))\n",
    "    \n",
    "    def z_loss(y_true,y_pred):\n",
    "        return K.mean(log_qz(y_true,y_pred) + -1*log_pz(y_true,y_pred))\n",
    "    \n",
    "    def x_loss(y_true,y_pred):\n",
    "        return K.mean(-log_px(y_true,y_pred))\n",
    "    \n",
    "    \n",
    "    loss = {'p_x':x_loss,'q_z':z_loss,'q_y':y_loss}\n",
    "    metrics = {'q_y':iou_coef}\n",
    "    model = Model([img_input,y_full], [x,y_output,z_sample], name = 'VAE')\n",
    "    model.compile(loss = loss,metrics = metrics,optimizer = keras.optimizers.Adam(lr=.1,clipnorm = 1.,clipvalue = 0.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 64, 64, 32)   288         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 32)   0           depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   512         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 96)   1536        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 96)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 32, 32, 96)   864         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 96)   0           depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 24)   2304        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 144)  3456        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 144)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 32, 32, 144)  1296        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 144)  0           depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 24)   3456        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 24)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 144)  3456        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 144)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 16, 16, 144)  1296        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 144)  0           depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4608        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 192)  6144        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 192)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 16, 16, 192)  1728        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   6144        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 32)   0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 192)  6144        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 192)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 16, 16, 192)  1728        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   6144        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 32)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 192)  6144        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 192)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 16, 16, 192)  1728        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   12288       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 384)  24576       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 384)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 16, 16, 384)  3456        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   24576       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 64)   0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 384)  24576       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 384)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 16, 16, 384)  3456        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   24576       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 384)  24576       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 384)  0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_10 (DepthwiseC (None, 16, 16, 384)  3456        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   24576       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 64)   0           add_5[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 384)  24576       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 384)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_11 (DepthwiseC (None, 16, 16, 384)  3456        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 96)   36864       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 576)  55296       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 576)  0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_12 (DepthwiseC (None, 16, 16, 576)  5184        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   55296       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 96)   0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 576)  55296       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 576)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_13 (DepthwiseC (None, 16, 16, 576)  5184        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 96)   55296       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 96)   0           add_7[0][0]                      \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 576)  55296       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 576)  0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_14 (DepthwiseC (None, 16, 16, 576)  5184        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 160)  92160       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 960)  153600      conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 960)  0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_15 (DepthwiseC (None, 16, 16, 960)  8640        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 160)  153600      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 160)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 960)  153600      add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 960)  0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_16 (DepthwiseC (None, 16, 16, 960)  8640        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 160)  153600      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 160)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 960)  153600      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 960)  0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_17 (DepthwiseC (None, 16, 16, 960)  8640        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 320)  307200      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 320)    0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 1, 256)    81920       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1, 1, 256)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 256)  81920       conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_1 (Bilinear (None, 16, 16, 256)  0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 256)  0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 512)  0           bilinear_upsampling_1[0][0]      \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 256)  131072      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 256)  0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 256)  0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 21)   5397        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_2 (Bilinear (None, 128, 128, 21) 0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "q_y (Activation)                (None, 128, 128, 21) 0           bilinear_upsampling_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 128, 128, 21) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               [(None, 128, 128, 21 0           q_y[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 128, 128, 21 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 128, 21) 0           lambda_2[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 21) 0           lambda_1[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 24) 0           concatenate_2[0][0]              \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 64, 64, 32)   6912        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 64, 64, 32)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_18 (DepthwiseC (None, 64, 64, 32)   288         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 64, 64, 32)   0           depthwise_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 64, 64, 16)   512         activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 64, 64, 96)   1536        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 64, 64, 96)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_19 (DepthwiseC (None, 32, 32, 96)   864         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 96)   0           depthwise_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 24)   2304        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 144)  3456        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 144)  0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_20 (DepthwiseC (None, 32, 32, 144)  1296        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 144)  0           depthwise_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 24)   3456        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 24)   0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 144)  3456        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 144)  0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_21 (DepthwiseC (None, 16, 16, 144)  1296        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 144)  0           depthwise_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 32)   4608        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 192)  6144        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 192)  0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_22 (DepthwiseC (None, 16, 16, 192)  1728        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   6144        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 32)   0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 192)  6144        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 192)  0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_23 (DepthwiseC (None, 16, 16, 192)  1728        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 32)   6144        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 32)   0           add_12[0][0]                     \n",
      "                                                                 conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 192)  6144        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 192)  0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_24 (DepthwiseC (None, 16, 16, 192)  1728        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 64)   12288       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 384)  24576       conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 384)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_25 (DepthwiseC (None, 16, 16, 384)  3456        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 64)   24576       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 64)   0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 384)  24576       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 384)  0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_26 (DepthwiseC (None, 16, 16, 384)  3456        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 64)   24576       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 64)   0           add_14[0][0]                     \n",
      "                                                                 conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 384)  24576       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 384)  0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_27 (DepthwiseC (None, 16, 16, 384)  3456        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 64)   24576       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 16, 16, 64)   0           add_15[0][0]                     \n",
      "                                                                 conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 384)  24576       add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 384)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_28 (DepthwiseC (None, 16, 16, 384)  3456        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 96)   36864       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 576)  55296       conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 576)  0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_29 (DepthwiseC (None, 16, 16, 576)  5184        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 96)   55296       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 16, 16, 96)   0           conv2d_60[0][0]                  \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 576)  55296       add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 576)  0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_30 (DepthwiseC (None, 16, 16, 576)  5184        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 96)   55296       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 16, 16, 96)   0           add_17[0][0]                     \n",
      "                                                                 conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 576)  55296       add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 576)  0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_31 (DepthwiseC (None, 16, 16, 576)  5184        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 160)  92160       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 960)  153600      conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 960)  0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_32 (DepthwiseC (None, 16, 16, 960)  8640        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 160)  153600      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 16, 160)  0           conv2d_66[0][0]                  \n",
      "                                                                 conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 960)  153600      add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 960)  0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_33 (DepthwiseC (None, 16, 16, 960)  8640        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 160)  153600      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 16, 16, 160)  0           add_19[0][0]                     \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 960)  153600      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 960)  0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_34 (DepthwiseC (None, 16, 16, 960)  8640        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 960)  0           depthwise_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 320)  307200      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 320)    0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 1, 1, 256)    81920       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1, 1, 256)    0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 256)  81920       conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_3 (Bilinear (None, 16, 16, 256)  0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 256)  0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 512)  0           bilinear_upsampling_3[0][0]      \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 256)  131072      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 256)  0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 256)  0           activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 21)   5397        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 21)   5397        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_5 (Bilinear (None, 128, 128, 21) 0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_4 (Bilinear (None, 128, 128, 21) 0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "q_z (Lambda)                    (None, 128, 128, 21) 0           bilinear_upsampling_5[0][0]      \n",
      "                                                                 bilinear_upsampling_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128, 128, 42) 0           q_z[0][0]                        \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 64, 64, 32)   12096       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 64, 64, 32)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_35 (DepthwiseC (None, 64, 64, 32)   288         activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 64, 64, 32)   0           depthwise_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 64, 64, 16)   512         activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 64, 64, 96)   1536        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 64, 64, 96)   0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_36 (DepthwiseC (None, 32, 32, 96)   864         activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 96)   0           depthwise_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 24)   2304        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 144)  3456        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 144)  0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_37 (DepthwiseC (None, 32, 32, 144)  1296        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 144)  0           depthwise_conv2d_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 24)   3456        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 32, 32, 24)   0           conv2d_81[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 32, 32, 144)  3456        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 32, 32, 144)  0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_38 (DepthwiseC (None, 16, 16, 144)  1296        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 144)  0           depthwise_conv2d_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 32)   4608        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 192)  6144        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 192)  0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_39 (DepthwiseC (None, 16, 16, 192)  1728        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 32)   6144        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 16, 16, 32)   0           conv2d_85[0][0]                  \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 192)  6144        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 192)  0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_40 (DepthwiseC (None, 16, 16, 192)  1728        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 32)   6144        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 16, 16, 32)   0           add_22[0][0]                     \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 192)  6144        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 192)  0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_41 (DepthwiseC (None, 16, 16, 192)  1728        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 192)  0           depthwise_conv2d_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 64)   12288       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 384)  24576       conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 384)  0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_42 (DepthwiseC (None, 16, 16, 384)  3456        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 64)   24576       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 16, 16, 64)   0           conv2d_91[0][0]                  \n",
      "                                                                 conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 16, 16, 384)  24576       add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 16, 16, 384)  0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_43 (DepthwiseC (None, 16, 16, 384)  3456        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 16, 16, 64)   24576       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 16, 16, 64)   0           add_24[0][0]                     \n",
      "                                                                 conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 384)  24576       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 16, 16, 384)  0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_44 (DepthwiseC (None, 16, 16, 384)  3456        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 64)   24576       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 16, 16, 64)   0           add_25[0][0]                     \n",
      "                                                                 conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 16, 16, 384)  24576       add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 16, 16, 384)  0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_45 (DepthwiseC (None, 16, 16, 384)  3456        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 16, 16, 384)  0           depthwise_conv2d_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 96)   36864       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 576)  55296       conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 16, 16, 576)  0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_46 (DepthwiseC (None, 16, 16, 576)  5184        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 16, 16, 576)  0           depthwise_conv2d_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 96)   55296       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 16, 16, 96)   0           conv2d_99[0][0]                  \n",
      "                                                                 conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 576)  55296       add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 576)  0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_47 (DepthwiseC (None, 16, 16, 576)  5184        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 576)  0           depthwise_conv2d_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 16, 16, 96)   0           add_27[0][0]                     \n",
      "                                                                 conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 576)  55296       add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 576)  0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_48 (DepthwiseC (None, 16, 16, 576)  5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 576)  0           depthwise_conv2d_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 160)  92160       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 960)  153600      conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 960)  0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_49 (DepthwiseC (None, 16, 16, 960)  8640        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 960)  0           depthwise_conv2d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 160)  153600      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 16, 16, 160)  0           conv2d_105[0][0]                 \n",
      "                                                                 conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 960)  153600      add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 960)  0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_50 (DepthwiseC (None, 16, 16, 960)  8640        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 960)  0           depthwise_conv2d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 160)  153600      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 16, 16, 160)  0           add_29[0][0]                     \n",
      "                                                                 conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 960)  153600      add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 960)  0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_51 (DepthwiseC (None, 16, 16, 960)  8640        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 960)  0           depthwise_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 320)  307200      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 1, 1, 320)    0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 1, 1, 256)    81920       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 1, 1, 256)    0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 256)  81920       conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_6 (Bilinear (None, 16, 16, 256)  0           activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 256)  0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 16, 16, 512)  0           bilinear_upsampling_6[0][0]      \n",
      "                                                                 activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 256)  131072      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 256)  0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 256)  0           activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 3)    771         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bilinear_upsampling_7 (Bilinear (None, 128, 128, 3)  0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_x (Activation)                (None, 128, 128, 3)  0           bilinear_upsampling_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 6,259,458\n",
      "Trainable params: 6,259,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = M2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines the augmentitations\n",
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "        A.Flip(p=0.5),\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),     \n",
    "        A.Resize(height = RESIZE, width = RESIZE, interpolation=1, always_apply=True, p=1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, always_apply=True, border_mode=0),\n",
    "        A.Resize(height = RESIZE, width = RESIZE, interpolation=1, always_apply=True, p=1)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for training\n",
    "class TrainGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in unlabeled images(file paths) and repeats the labeled images until they're\n",
    "    # are more labeled ones then unlabeled ones\n",
    "    def __init__(self,  n_classes=21, batch_size=32, resize_shape=(RESIZE,RESIZE)):\n",
    "        \n",
    "        self.image_path_list = os.listdir('./VOCdevkit/VOC2012/train_frames/')\n",
    "        self.unsupervised_path_list = os.listdir('./VOCdevkit/VOC2012/JPEGImages/')\n",
    "        \n",
    "        random.shuffle(self.image_path_list)\n",
    "        random.shuffle(self.unsupervised_path_list)\n",
    "          \n",
    "        lis = os.listdir('./VOCdevkit/VOC2012/train_frames/')\n",
    "        while len(self.image_path_list) <= len(self.unsupervised_path_list):\n",
    "            random.shuffle(lis)\n",
    "            self.image_path_list.extend(lis)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = int(batch_size/2)\n",
    "        self.resize_shape = resize_shape\n",
    "        if self.resize_shape:\n",
    "            self.X = np.zeros((self.batch_size*2, resize_shape[1], resize_shape[0], 3), dtype='float32')\n",
    "            self.Y = np.zeros((self.batch_size*2, resize_shape[1],resize_shape[0],n_classes), dtype='float32')\n",
    "        else:\n",
    "            raise Exception('No image dimensions specified!')\n",
    "    \n",
    "    # Number of epochs is number of unlabeled images divided by the batch size\n",
    "    def __len__(self):\n",
    "        return  len(self.unsupervised_path_list) // self.batch_size \n",
    "        \n",
    "    # Fetches batch treating image as a matrix of the parameters \n",
    "    # to independent bernoulli distributed random variables, which are\n",
    "    # then sampled from to create a dynamic discretization of the data.\n",
    "    # Also dummy encodes the mask.\n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        \n",
    "        for x in self.image_path_list[i*self.batch_size:(i+1)*self.batch_size]:\n",
    "            \n",
    "            image = np.array(Image.open('./VOCdevkit/VOC2012/train_frames/' + x))\n",
    "            label = np.array(Image.open('./VOCdevkit/VOC2012/train_masks/' + x.replace('.jpg','.png')))\n",
    "\n",
    "            sample = get_training_augmentation()(image=image, mask=label)\n",
    "            image, label = sample['image']/255,sample['mask']\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "            categorical_label = keras.utils.to_categorical(label)\n",
    "\n",
    "            self.X[n] = image\n",
    "            #cat_label -> image\n",
    "            self.Y[n] = categorical_label[:,:,0:21]\n",
    "            n = n + 1\n",
    "            \n",
    "        for x in self.unsupervised_path_list[i*self.batch_size:(i+1)*self.batch_size]:\n",
    "    \n",
    "            image = np.array(Image.open('./VOCdevkit/VOC2012/JPEGImages/' + x))\n",
    "\n",
    "            sample = get_training_augmentation()(image=image)\n",
    "            image= sample['image']/255\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "\n",
    "            self.X[n] = image\n",
    "            n = n + 1\n",
    "\n",
    "        return [self.X, self.Y] , [self.Y,self.Y,self.Y]\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.unsupervised_path_list)\n",
    "        self.image_path_list = os.listdir('./VOCdevkit/VOC2012/train_frames/')\n",
    "        lis = os.listdir('./VOCdevkit/VOC2012/train_frames/')\n",
    "        while len(self.image_path_list) <= len(self.unsupervised_path_list):\n",
    "            random.shuffle(lis)\n",
    "            self.image_path_list.extend(lis)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the data used for validation\n",
    "class ValGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    # Loads in the labeled images\n",
    "    def __init__(self,  n_classes=21, batch_size=32, resize_shape=(RESIZE,RESIZE)):\n",
    "            \n",
    "        self.image_path_list = os.listdir('./VOCdevkit/VOC2012/val_frames/')\n",
    "        random.shuffle(self.image_path_list)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = int(batch_size/2)\n",
    "        self.resize_shape = resize_shape\n",
    "        if self.resize_shape:\n",
    "            self.X = np.zeros((self.batch_size*2, resize_shape[1], resize_shape[0], 3), dtype='float32')\n",
    "            self.Y = np.zeros((self.batch_size*2, resize_shape[1],resize_shape[0],n_classes), dtype='float32')\n",
    "        else:\n",
    "            raise Exception('No image dimensions specified!')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_path_list) // self.batch_size\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        n = 0\n",
    "        \n",
    "        for x in self.image_path_list[i*self.batch_size:(i+1)*self.batch_size]:\n",
    "            \n",
    "            image = np.array(Image.open('./VOCdevkit/VOC2012/val_frames/' + x))\n",
    "            label = np.array(Image.open('./VOCdevkit/VOC2012/val_masks/' + x.replace('.jpg','.png')))\n",
    "\n",
    "            sample = get_validation_augmentation()(image=image, mask=label)\n",
    "            image, label = sample['image']/255, sample['mask']\n",
    "            rand = np.random.ranf(image.shape)\n",
    "            image = np.greater(image,rand).astype(int)\n",
    "\n",
    "            categorical_label = keras.utils.to_categorical(label)\n",
    "\n",
    "            self.X[n] = image\n",
    "            #cat_label -> image\n",
    "            self.Y[n] = categorical_label[:,:,0:21]\n",
    "            n = n + 1\n",
    "\n",
    "        return [self.X, self.Y] , [self.Y,self.Y,self.Y]\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.image_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates training and validition generators\n",
    "train_gen = TrainGenerator(batch_size = BATCH_SIZE,n_classes = CLASSES)\n",
    "val_gen = ValGenerator(batch_size = BATCH_SIZE,n_classes = CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/judah/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "1776/1776 [==============================] - 501s 282ms/step - loss: 10214196.8846 - p_x_loss: 77.7881 - q_y_loss: 10213884.7449 - q_z_loss: 234.3467 - q_y_iou_coef: 0.5060 - val_loss: 10266928.6374 - val_p_x_loss: 66.9521 - val_q_y_loss: 10266676.8819 - val_q_z_loss: 184.8522 - val_q_y_iou_coef: 0.5691\n",
      "Epoch 2/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9940605.8347 - p_x_loss: 77.6908 - q_y_loss: 9940385.5695 - q_z_loss: 142.5898 - q_y_iou_coef: 0.5106 - val_loss: 10172041.6016 - val_p_x_loss: 56.9749 - val_q_y_loss: 10171972.4918 - val_q_z_loss: 12.1591 - val_q_y_iou_coef: 0.5372\n",
      "Epoch 3/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9926876.2469 - p_x_loss: 77.7139 - q_y_loss: 9926650.9398 - q_z_loss: 147.5857 - q_y_iou_coef: 0.5118 - val_loss: 10309452.5330 - val_p_x_loss: 60.3353 - val_q_y_loss: 10309384.2253 - val_q_z_loss: 7.9940 - val_q_y_iou_coef: 0.5542\n",
      "Epoch 4/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9962076.0622 - p_x_loss: 77.7373 - q_y_loss: 9961577.6475 - q_z_loss: 420.6844 - q_y_iou_coef: 0.5095 - val_loss: 10629166.2720 - val_p_x_loss: 60.5734 - val_q_y_loss: 10626634.7582 - val_q_z_loss: 2470.9135 - val_q_y_iou_coef: 0.4111\n",
      "Epoch 5/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9933528.2979 - p_x_loss: 77.7114 - q_y_loss: 9933276.8384 - q_z_loss: 173.7558 - q_y_iou_coef: 0.5103 - val_loss: 10056912.5604 - val_p_x_loss: 60.7113 - val_q_y_loss: 10056832.9121 - val_q_z_loss: 18.9743 - val_q_y_iou_coef: 0.5343\n",
      "Epoch 6/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9921872.3573 - p_x_loss: 77.7384 - q_y_loss: 9921640.8184 - q_z_loss: 153.7994 - q_y_iou_coef: 0.5114 - val_loss: 10387961.7280 - val_p_x_loss: 61.8888 - val_q_y_loss: 10387461.5962 - val_q_z_loss: 438.2436 - val_q_y_iou_coef: 0.5750\n",
      "Epoch 7/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9914202.1436 - p_x_loss: 77.7174 - q_y_loss: 9913953.6137 - q_z_loss: 170.8064 - q_y_iou_coef: 0.5111 - val_loss: 9959596.8379 - val_p_x_loss: 63.9355 - val_q_y_loss: 9959523.5110 - val_q_z_loss: 9.4386 - val_q_y_iou_coef: 0.5302\n",
      "Epoch 8/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9930760.8725 - p_x_loss: 77.7575 - q_y_loss: 9930522.9313 - q_z_loss: 160.1755 - q_y_iou_coef: 0.5112 - val_loss: 10007526.3516 - val_p_x_loss: 66.1740 - val_q_y_loss: 10007410.5907 - val_q_z_loss: 49.5290 - val_q_y_iou_coef: 0.5056\n",
      "Epoch 9/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9938920.3105 - p_x_loss: 77.7319 - q_y_loss: 9938604.6222 - q_z_loss: 237.9603 - q_y_iou_coef: 0.5108 - val_loss: 10142401.9863 - val_p_x_loss: 62.1335 - val_q_y_loss: 10142307.4478 - val_q_z_loss: 32.3532 - val_q_y_iou_coef: 0.5144\n",
      "Epoch 10/10\n",
      "1776/1776 [==============================] - 481s 271ms/step - loss: 9936734.4783 - p_x_loss: 77.7198 - q_y_loss: 9936522.7342 - q_z_loss: 134.0384 - q_y_iou_coef: 0.5113 - val_loss: 10389367.7692 - val_p_x_loss: 63.2056 - val_q_y_loss: 10389265.3187 - val_q_z_loss: 39.2594 - val_q_y_iou_coef: 0.5058\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n"
     ]
    }
   ],
   "source": [
    "# Saves the model best weights to a file \n",
    "checkpoint = ModelCheckpoint(\n",
    "    'NEW_Pascal_Voc_M2_VAE.h5', \n",
    "    monitor='val_q_y_iou_coef', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    period = 1\n",
    ")\n",
    "\n",
    "# Reduces the learning rate when the model has stoped learning\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss',patience = 3 ,factor = .5,verbose = 1)\n",
    "\n",
    "\n",
    "# Trains the model for 10 epochs\n",
    "history = model.fit_generator(\n",
    "    generator = train_gen,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[checkpoint,reduce_lr],\n",
    "    use_multiprocessing=False,\n",
    "    workers=1,\n",
    "    epochs=10 ,\n",
    "    max_queue_size = 10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
